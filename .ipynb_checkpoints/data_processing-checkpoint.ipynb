{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random blur and random brightness adjustment to be added.\n",
    "## About normalization we need to check in which values we normalize -> later\n",
    "data_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop((640, 512)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_out_map(img_name, features, objects_to_look = ['ball'], ratio = 4):\n",
    "        # ratio is the input-output ratio\n",
    "        f = features[(features['image_file']==img_name) & (features.label.isin(objects_to_look))]\n",
    "        out_map = torch.zeros((160, 128))\n",
    "\n",
    "        for i in range(len(f)):\n",
    "            temp = f.iloc[i]\n",
    "            x_object = (temp['xmin'] + temp['xmax'])/(ratio*2) # /2 because you the middle, /4 because of the ratio with original img\n",
    "            y_object = (temp['ymin'] + temp['ymax'])/(ratio*2) # /2 because you the middle, /4 because of the ratio with original img\n",
    "            current_value = out_map[x_object.astype(int), y_object.astype(int)]\n",
    "            if current_value == 0 or current_value < 1:\n",
    "                out_map[x_object.astype(int), y_object.astype(int)] = 1\n",
    "\n",
    "        #TODO: how to spread this one as a gaussian from the center, need discussion\n",
    "        return out_map \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoccerBallDetection(Dataset):\n",
    "    \"\"\"Soccer Ball dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None, objects_to_look = ['ball']):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.features = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Loading image\n",
    "        img_name = self.features.iloc[idx, 0]\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        image = io.imread(img_path)\n",
    "        \n",
    "        # Extracting features\n",
    "        sample = {'image': image, 'features': generate_out_map(img_name, features)}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('data/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SoccerBallDetection('data/data.csv', 'data/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01882794, 0.09955906, 0.01882794],\n",
       "       [0.09955906, 0.52645199, 0.09955906],\n",
       "       [0.01882794, 0.09955906, 0.01882794]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import scipy.stats as st\n",
    "\n",
    "# def gkern(kernlen=5, nsig=3):\n",
    "#     \"\"\"Returns a 2D Gaussian kernel array.\"\"\"\n",
    "\n",
    "#     interval = (2*nsig+1.)/(kernlen)\n",
    "#     x = np.linspace(-nsig-interval/2., nsig+interval/2., kernlen+1)\n",
    "#     kern1d = np.diff(st.norm.cdf(x))\n",
    "#     kernel_raw = np.sqrt(np.outer(kern1d, kern1d))\n",
    "#     kernel = kernel_raw/kernel_raw.sum()\n",
    "#     return kernel\n",
    "# gkern(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=4,\n",
    "                        shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x129b387b8>\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x129b387b8>\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "    self._shutdown_workers()\n",
      "    w.join()\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "  File \"/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    w.join()\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "  File \"/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "AssertionError: can only join a child process\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x129b387b8>\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x129b387b8>\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "Traceback (most recent call last):\n",
      "    self._shutdown_workers()\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "    self._shutdown_workers()\n",
      "    w.join()\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "  File \"/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    w.join()\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "  File \"/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "AssertionError: can only join a child process\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x129b387b8>\n",
      "AssertionError: can only join a child process\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x129b387b8>\n",
      "    self._shutdown_workers()\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "    w.join()\n",
      "    self._shutdown_workers()\n",
      "  File \"/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "    w.join()\n",
      "AssertionError: can only join a child process\n",
      "  File \"/anaconda3/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n",
      "Exception ignored in: <function _DataLoaderIter.__del__ at 0x129b387b8>\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 717, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 713, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/anaconda3/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/anaconda3/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/anaconda3/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "Traceback (most recent call last):\n  File \"/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-24-145da1d44d30>\", line 26, in __getitem__\n    sample = {'image': image, 'features': generate_out_map(img_name, features)}\nNameError: name 'features' is not defined\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-bdeaa8df5576>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_batched\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     print(i_batch, sample_batched['image'].size(),\n\u001b[1;32m      3\u001b[0m           sample_batched['features'].size())\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_batch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: Traceback (most recent call last):\n  File \"/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 138, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-24-145da1d44d30>\", line 26, in __getitem__\n    sample = {'image': image, 'features': generate_out_map(img_name, features)}\nNameError: name 'features' is not defined\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(i_batch, sample_batched['image'].size(),\n",
    "          sample_batched['features'].size())\n",
    "    if(i_batch > 1):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
