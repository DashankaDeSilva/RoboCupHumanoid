{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_processing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "XOowNhm8EuA5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dJ1ATjqYM2I3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install pillow==4.1.1\n",
        "%reload_ext autoreload\n",
        "%autoreload"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mArCYT8OM4D-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.utils.data\n",
        "from torchvision import datasets, models, transforms\n",
        "import os\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torchvision.transforms.functional as TF\n",
        "import scipy.stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ettpyR3gErDt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Random blur and random brightness adjustment to be added.\n",
        "## About normalization we need to check in which values we normalize -> later\n",
        "data_transforms = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AelHbSp_ErDw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_teacher_signal(features, img_name, width, height, sigma=4, downsample=4):\n",
        "        f = features[(features['image_file']==img_name) & (features.label.isin(objects_to_look))]\n",
        "        print(width, height)\n",
        "        \"\"\"Creates teacher signal for the image.\"\"\"\n",
        "        signal = torch.zeros((height, width))\n",
        "\n",
        "        for i in range(len(f)):\n",
        "            temp = f.iloc[i]\n",
        "            xmin = temp['xmin']\n",
        "            xmax = temp['xmax']\n",
        "            ymin = temp['ymin']\n",
        "            ymax = temp['ymax']\n",
        "            \n",
        "            c_x = int((xmax + xmin) / 2)\n",
        "            c_y = int((ymax + ymin) / 2)\n",
        "\n",
        "            for y in range(ymin, ymax + 1):\n",
        "                for x in range(xmin, xmax + 1):\n",
        "                    signal[y, x] += scipy.stats.multivariate_normal.pdf([y, x], [c_y, c_x], [sigma, sigma])\n",
        "      \n",
        "\n",
        "        # downsample\n",
        "        signal = signal[::downsample, ::downsample]\n",
        "        return signal\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jo9ufku1ErDz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SoccerBallDataset(Dataset):\n",
        "    \"\"\"Soccer Ball dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, root_dir, transform=None, objects_to_look = ['ball']):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.features = pd.read_csv(csv_file,sep=';' )\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.objects_to_look = objects_to_look\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Loading image\n",
        "        img_name = self.features.iloc[idx, 0]\n",
        "        img_path = os.path.join(self.root_dir, img_name)\n",
        "        image = io.imread(img_path)\n",
        "        image = image.transpose(2,0,1)\n",
        "        image = torch.from_numpy(image)\n",
        "\n",
        "        if self.transform:\n",
        "            image = TF.to_pil_image(image)\n",
        "            image = self.transform(image)\n",
        "            \n",
        "        # Extracting features\n",
        "        sample = {'image': image, 'features': self.get_teacher_signal(img_name, image.size()[2], image.size()[1])}\n",
        "\n",
        "        return sample\n",
        "    \n",
        "    def get_teacher_signal(self, img_name, width, height, sigma=4, downsample=4):\n",
        "        f = self.features[(self.features['image_file']==img_name) & (self.features.label.isin(self.objects_to_look))]\n",
        "        \"\"\"Creates teacher signal for the image.\"\"\"\n",
        "        signal = torch.zeros((height, width))\n",
        "\n",
        "        for i in range(len(f)):\n",
        "            temp = f.iloc[i]\n",
        "            xmin = temp['xmin']\n",
        "            xmax = temp['xmax']\n",
        "            ymin = temp['ymin']\n",
        "            ymax = temp['ymax']\n",
        "            \n",
        "            c_x = int((xmax + xmin) / 2)\n",
        "            c_y = int((ymax + ymin) / 2)\n",
        "\n",
        "            for y in range(ymin, ymax + 1):\n",
        "                for x in range(xmin, xmax + 1):\n",
        "                    signal[y, x] += scipy.stats.multivariate_normal.pdf([y, x], [c_y, c_x], [sigma, sigma])\n",
        "      \n",
        "\n",
        "        # downsample\n",
        "        signal = signal[::downsample, ::downsample]\n",
        "        return signal\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hip0nxCZErD5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# upload files if google colab !mkdir data/train\n",
        "dataset = SoccerBallDataset('data/data_10.csv', 'data/train', transform=data_transforms)\n",
        "dataloader = DataLoader(dataset, batch_size=4,\n",
        "                        shuffle=True, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fxmSNjtEErEF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "bb2e5d8a-35d2-4141-d73a-1a7ddf7aac06"
      },
      "cell_type": "code",
      "source": [
        "# Just testing \n",
        "for i_batch, sample_batched in enumerate(dataloader):\n",
        "    print(i_batch, sample_batched['image'].size(),\n",
        "          sample_batched['features'].size())\n",
        "    if(i_batch > 1):\n",
        "        break"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 torch.Size([4, 3, 480, 640]) torch.Size([4, 120, 160])\n",
            "1 torch.Size([4, 3, 480, 640]) torch.Size([4, 120, 160])\n",
            "2 torch.Size([4, 3, 480, 640]) torch.Size([4, 120, 160])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qILaCN5jMrGS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}