{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_processing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "XOowNhm8EuA5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dJ1ATjqYM2I3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install pillow==4.1.1\n",
        "%reload_ext autoreload\n",
        "%autoreload"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mArCYT8OM4D-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.utils.data\n",
        "from torchvision import datasets, models, transforms\n",
        "import os\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torchvision.transforms.functional as TF"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ettpyR3gErDt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Random blur and random brightness adjustment to be added.\n",
        "## About normalization we need to check in which values we normalize -> later\n",
        "data_transforms = transforms.Compose([\n",
        "        transforms.Resize((640, 512)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AelHbSp_ErDw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_out_map(img_name, features, objects_to_look = ['ball'], ratio = 4):\n",
        "        # ratio is the input-output ratio\n",
        "        f = features[(features['image_file']==img_name) & (features.label.isin(objects_to_look))]\n",
        "        out_map = torch.zeros((160, 128))\n",
        "\n",
        "        for i in range(len(f)):\n",
        "            temp = f.iloc[i]\n",
        "            x_object = (temp['xmin'] + temp['xmax'])/(ratio*2) # /2 because you the middle, /4 because of the ratio with original img\n",
        "            y_object = (temp['ymin'] + temp['ymax'])/(ratio*2) # /2 because you the middle, /4 because of the ratio with original img\n",
        "            current_value = out_map[x_object.astype(int), y_object.astype(int)]\n",
        "            if current_value == 0 or current_value < 1:\n",
        "                out_map[x_object.astype(int), y_object.astype(int)] = 1\n",
        "\n",
        "        # TODO: how to spread this one as a gaussian from the center, need discussion\n",
        "        return out_map \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jo9ufku1ErDz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SoccerBallDetection(Dataset):\n",
        "    \"\"\"Soccer Ball dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, root_dir, transform=None, objects_to_look = ['ball']):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.features = pd.read_csv(csv_file,sep=';' )\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Loading image\n",
        "        img_name = self.features.iloc[idx, 0]\n",
        "        img_path = os.path.join(self.root_dir, img_name)\n",
        "        image = io.imread(img_path)\n",
        "        image = torch.from_numpy(image)\n",
        "        \n",
        "        if self.transform:\n",
        "            image = TF.to_pil_image(image)\n",
        "            image = self.transform(image)\n",
        "        # Extracting features\n",
        "        sample = {'image': image, 'features': generate_out_map(img_name, self.features)}\n",
        "\n",
        "        \n",
        "\n",
        "        return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hip0nxCZErD5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# upload files if google colab !mkdir data/train\n",
        "dataset = SoccerBallDetection('data/data_10.csv', 'data/train', transform=data_transforms)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "an3EgUQvErD7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import scipy.stats as st\n",
        "\n",
        "# def gkern(kernlen=5, nsig=3):\n",
        "#     \"\"\"Returns a 2D Gaussian kernel array.\"\"\"\n",
        "\n",
        "#     interval = (2*nsig+1.)/(kernlen)\n",
        "#     x = np.linspace(-nsig-interval/2., nsig+interval/2., kernlen+1)\n",
        "#     kern1d = np.diff(st.norm.cdf(x))\n",
        "#     kernel_raw = np.sqrt(np.outer(kern1d, kern1d))\n",
        "#     kernel = kernel_raw/kernel_raw.sum()\n",
        "#     return kernel\n",
        "# gkern(3, 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TVub_a_LErEA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=4,\n",
        "                        shuffle=True, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fxmSNjtEErEF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f1e09e3b-8ea2-44c3-f3c6-5bc6538dd72e"
      },
      "cell_type": "code",
      "source": [
        "# Just testing \n",
        "for i_batch, sample_batched in enumerate(dataloader):\n",
        "    print(i_batch, sample_batched['image'].size(),\n",
        "          sample_batched['features'].size())\n",
        "    if(i_batch > 1):\n",
        "        break"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 torch.Size([4, 3, 640, 512]) torch.Size([4, 160, 128])\n",
            "1 torch.Size([4, 3, 640, 512]) torch.Size([4, 160, 128])\n",
            "2 torch.Size([4, 3, 640, 512]) torch.Size([4, 160, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qILaCN5jMrGS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}